# AI Tools

Recent generative AI tools have reached an impressive level. In particular, large language models (e.g., GPT-4) show an impressive ability to generate text, and tools like ChatGPT make it easy to prompt and interact with such models. We are agnostic about the use of such tools during the ExPra. We believe such tools can be useful, but may also impede learning and assessment if not used responsibly.

We are having to adapt the way that we design and evaluate assessments to ensure that we are assessing your knowledge and ability, and not participating in a Turing test.

## Uses of AI we will allow

We will **allow** usage of AI tools in some cases, if you find it useful:

* Rephrasing text and spelling/grammar check (e.g., DeepL Write, Grammarly)

* Translating text (e.g., DeepL Translator)

* Literature search & article summary (e.g., Elicit) alongside independent reading

* 'Brainstorming' on a topic (e.g., using ChatGPT)

* Image generation (e.g., DALL-E)

## Uses of AI we will not allow

We will **not allow** usage of AI tools in the following cases:

* Generating/writing text/code that goes beyond just rephrasing content you have written yourself (“An independent examination performance no longer exists if the results are not based on one's own knowledge, i.e. the knowledge required to solve the examination performance does not come from the students”)

* Using AI as a citable source, for example: “Priming is a psychological phenomenon where exposure to one stimulus influences a person's response to a subsequent stimulus, often without conscious awareness (Output by ChatGPT, 02.08.2024)”.

## How should use of AI tools be recorded?

This year, you will be required to include a signed declaration of originality in your reports that includes the requirement to declare any aids used.

Please add the following section to the standard Declaration of Originality (*Eigenständigkeitserklärung; for a template see [FAQs by the examination office](https://www.psychologie.uni-frankfurt.de/126118252/BSc_MSc_FAQ_Okt_2022.pdf)*):

> I am aware that the use of texts generated by AI tools does not guarantee the quality of content and text. I therefore declare that I have only used text-generating AI tools as an aid, but that the ideas and work are predominantly my own. Furthermore, I declare that I have marked all text passages that were written with the aid of AI-supported programs accordingly and provided a reference to the AI-supported program used. I declare that I have not used AI tools for purposes that the examiner has not explicitly allowed.

You should also include a **List of AI Tools Used**, after the literature list:

* **Name, version and provider of the tool** (company, organization or person that offers or programmed the tool)

* **Purpose of using the tool** (e.g., translation, rephrasing, grammar/spelling check)

* **Affected text segments** (e.g., Discussion section or p. 14)

* **Date of content generation**

* **URL of the tool**

* **Complete prompt and output**: The complete prompt (user input) and output created by AI should be provided to make the exact use of AI and your own contribution transparent.

## Recommendations in case we get it wrong

There is no reliable method for detecting the use of AI, but we are required to report any suspicions of deception to the examination board. As a result, there is a chance we might get it wrong.

To avoid this situation, we very highly recommend the following steps, so that you will be able to demonstrate that your report is your own work:

* Save separate versions of your report, with time stamps, ona  daily basis

* Save all input prompts and outputs created by any AI tools that you used.

## Tips for Using Large Language Models in Academia

One particular difficulty with tools like ChatGPT is that they can produce outputs that appear highly fluent and confident, even when the output is wrong. While tools like this can be useful for brainstorming, any suggestions they make should be checked thoroughly.

These models are trained on large amounts of text available on the internet, and are trained to generate new text like that they have seen before. This will include some trustworthy academic sources, but also text from (e.g.,) forum interactions, blog posts, pop science articles, etc.. Just as you would not uncritically trust or cite such sources, you should not uncritically trust or cite the output from platforms like ChatGPT.

Common issues with large language models:

* Citations that these models produce can be either "hallucinated" (made up) or misattributed (the source they cite didn't really say what the output claims).

* Outputs can be wrong in more subtle ways, such as conflating concepts, failing to evaluate the consequences of some code, or just misunderstanding the purpose of a prompt.

If you prompt a large language model, in addition to the info above, we recommend that you:

1. Check any citations or sources it provides - did those researchers really say or find what the output claims?

2. Try to find original sources that discuss and evaluate research relevant to the output's claims. The output will often provide key words that you can use in your literature searches.

3. Do independent research into any topics or research you are not already familiar with, to make sure you understand it yourself, so that you avoid reproducing misunderstandings in the output.

4. Reflect critically on the output, and relate it to your own knowledge.

##### Acknmowledgements

Parts of this text are adapted from text by Sandro Wiesmann, and based on a guide by [Goethe University Lehre virtuell](https://lehre-virtuell.uni-frankfurt.de/knowhow/einsatz-von-generativer-ki-in-der-lehre-handlungsempfehlungen-fur-lehrende/#hinweise-zum-umgang-mit-verdachtsfaellen-zum-unzulaessigen-einsatz-von-ki-tools-in-schriftlichen-arbeiten).
